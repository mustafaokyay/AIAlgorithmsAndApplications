{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 1 Exercise 2: \"Introduction to Python\"\n",
    "\n",
    "## 2.3 Wine Quality\n",
    "\n",
    "#### a) You import the data and start exploring to gather a better understanding of it by checking, e.g., data types, number of columns and rows, number of missing values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1594</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the data\n",
    "wine = pd.read_csv(\"wineQuality.csv\")\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an overview of the data\n",
    "wine.info()\n",
    "wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Then, you decide to bin the “quality” column into two categories “mediocre” and “excellent”. However, before you do, you have to get an overview of the quality values and their distribution by visualizing them in a fitting plot. How many data points did you place in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "4     53\n",
      "8     18\n",
      "3     10\n",
      "Name: quality, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff77d9ddc10>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting an overview\n",
    "count=wine[\"quality\"].value_counts()\n",
    "quality=pd.Series(wine[\"quality\"])\n",
    "quality=quality.sort_values(ascending=True)\n",
    "print(count)\n",
    "fig, chart = plt.subplots(2, 2, figsize=(5,5))\n",
    "chart[0,0].hist(quality)\n",
    "chart[1,0].pie(count)\n",
    "chart[1,1].plot(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mediocre, excellent]\n",
       "Categories (2, object): [mediocre < excellent]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the two bins\n",
    "bins=(2,5.9,8)\n",
    "groups=['mediocre','excellent']\n",
    "wine['quality']=pd.cut(wine['quality'],bins=bins,labels=groups)\n",
    "\n",
    "wine['quality'].unique() # just to display the below output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    855\n",
      "1    744\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wine['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Afterwards, you set the “quality” column as the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 1, 5, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing as spp\n",
    "\n",
    "LE=spp.LabelEncoder()\n",
    "wine['quality']=LE.fit_transform(wine['quality'])\n",
    "\n",
    "#wine['quality'].value_counts()\n",
    "wine['quality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Then, you decide to scale the data using the scikit-learn function “StandardScaler”. What does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED DATA:\n",
      "[[-0.52835961  0.96187667 -1.39147228 ...  1.28864292 -0.57920652\n",
      "  -0.96024611]\n",
      " [-0.29854743  1.96744245 -1.39147228 ... -0.7199333   0.1289504\n",
      "  -0.58477711]\n",
      " [-0.29854743  1.29706527 -1.18607043 ... -0.33117661 -0.04808883\n",
      "  -0.58477711]\n",
      " ...\n",
      " [-1.1603431  -0.09955388 -0.72391627 ...  0.70550789  0.54204194\n",
      "   0.54162988]\n",
      " [-1.39015528  0.65462046 -0.77526673 ...  1.6773996   0.30598963\n",
      "  -0.20930812]\n",
      " [-1.33270223 -1.21684919  1.02199944 ...  0.51112954  0.01092425\n",
      "   0.54162988]]\n",
      "NON-SCALED DATA:\n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4             0.700         0.00             1.9      0.076   \n",
      "1               7.8             0.880         0.00             2.6      0.098   \n",
      "2               7.8             0.760         0.04             2.3      0.092   \n",
      "3              11.2             0.280         0.56             1.9      0.075   \n",
      "4               7.4             0.700         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1594            6.2             0.600         0.08             2.0      0.090   \n",
      "1595            5.9             0.550         0.10             2.2      0.062   \n",
      "1596            6.3             0.510         0.13             2.3      0.076   \n",
      "1597            5.9             0.645         0.12             2.0      0.075   \n",
      "1598            6.0             0.310         0.47             3.6      0.067   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        1  \n",
      "1         9.8        1  \n",
      "2         9.8        1  \n",
      "3         9.8        0  \n",
      "4         9.4        1  \n",
      "...       ...      ...  \n",
      "1594     10.5        1  \n",
      "1595     11.2        0  \n",
      "1596     11.0        0  \n",
      "1597     10.2        1  \n",
      "1598     11.0        0  \n",
      "\n",
      "[1599 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "wine_pre_scale = wine  # if you want to compare the original data later\n",
    "\n",
    "scaler=spp.StandardScaler()\n",
    "X = wine.drop('quality',axis=1) # Remove target variable which will be handled separately later\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print(\"SCALED DATA:\")\n",
    "print(X)\n",
    "\n",
    "print(\"NON-SCALED DATA:\")\n",
    "print(wine_pre_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) To finalize your preprocessing, you split the data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[ 2.34429261 -0.99339013  1.12470036 ... -1.23827555  0.54204194\n",
      "  -0.02157362]\n",
      " [-0.93053092  1.2412005  -1.34012182 ...  1.54781404 -0.28414114\n",
      "   2.23124036]\n",
      " [-0.98798397  0.57082331 -1.39147228 ... -0.7199333  -1.22835037\n",
      "  -0.86637886]\n",
      " ...\n",
      " [-0.6432657   0.51495855 -1.08336951 ...  1.28864292 -0.69723268\n",
      "  -0.86637886]\n",
      " [-0.24109439 -1.83136161  0.4057939  ...  0.05758008  0.83710732\n",
      "   1.38643512]\n",
      " [-1.44760832 -1.32857872 -0.05636026 ...  0.51112954 -0.69723268\n",
      "   2.8883111 ]]\n",
      "-----\n",
      "X_test:\n",
      "[[-0.35600048  0.17976995 -0.98066858 ... -0.46076217  0.01092425\n",
      "  -0.77251161]\n",
      " [-0.29854743 -0.15541864 -0.51851442 ...  0.51112954 -1.05131114\n",
      "  -0.86637886]\n",
      " [ 1.36759086  0.79428237 -0.26176211 ... -0.20159105  1.89934271\n",
      "  -0.49090986]\n",
      " ...\n",
      " [-0.01128221 -1.21684919  0.61119574 ... -0.0072127   0.66006809\n",
      "   1.94963861]\n",
      " [-0.06873526  4.48135691 -1.39147228 ...  1.41822848 -0.99229806\n",
      "   0.44776263]\n",
      " [ 0.44834214  0.73841761 -0.62121535 ... -0.20159105 -0.69723268\n",
      "  -0.77251161]]\n",
      "-----\n",
      "y_train:\n",
      "548     0\n",
      "355     0\n",
      "1296    1\n",
      "209     0\n",
      "140     1\n",
      "       ..\n",
      "1130    0\n",
      "1294    0\n",
      "860     1\n",
      "1459    0\n",
      "1126    0\n",
      "Name: quality, Length: 1071, dtype: int64\n",
      "-----\n",
      "y_test:\n",
      "803     0\n",
      "124     1\n",
      "350     0\n",
      "682     1\n",
      "1326    0\n",
      "       ..\n",
      "813     1\n",
      "377     0\n",
      "898     0\n",
      "126     1\n",
      "819     1\n",
      "Name: quality, Length: 528, dtype: int64\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "y = wine['quality'] # Target variable (was previously removed from X)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"X_test:\")\n",
    "print(X_test)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"y_test:\")\n",
    "print(y_test)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) You decide to train several models using the following algorithms: Decision Tree, Random Forest, Support Vector Machine, Neural Network, and Linear Regression.\n",
    "\n",
    "\n",
    "**NOTE:** You will receive a warning that you neural network has not converged yet. To resolve this, you can increase the number of iterations which will lead to a longer run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timosturm/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and Apply on Test Data for the differnt algorithms\n",
    "\n",
    "# DECISION TREE\n",
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train,y_train)\n",
    "dt_predict = dt.predict(X_test)\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=150)\n",
    "forest.fit(X_train, y_train)\n",
    "forest_predict = forest.predict(X_test)\n",
    "\n",
    "\n",
    "# SUPPORT VECTOR MACHINE\n",
    "import sklearn.svm as svm\n",
    "\n",
    "sup = svm.SVC(gamma='auto')\n",
    "sup.fit(X_train, y_train)\n",
    "sup_predict=sup.predict(X_test)\n",
    "\n",
    "\n",
    "# NEURAL NETWORK (MLP = Multi-layer Perceptron)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(15), random_state=1)\n",
    "nn.fit(X_train, y_train)\n",
    "nn_predict = nn.predict(X_test)\n",
    "\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# X2_test = scaler.transform(X2_test)   EVENTUELL ANWENDEN!!!\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "LR_predict = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DECISION TREE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       290\n",
      "           1       0.70      0.70      0.70       238\n",
      "\n",
      "    accuracy                           0.73       528\n",
      "   macro avg       0.72      0.72      0.72       528\n",
      "weighted avg       0.73      0.73      0.73       528\n",
      "\n",
      "[[217  73]\n",
      " [ 71 167]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7272727272727273\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "2. RANDOM FOREST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       290\n",
      "           1       0.79      0.75      0.77       238\n",
      "\n",
      "    accuracy                           0.80       528\n",
      "   macro avg       0.80      0.79      0.79       528\n",
      "weighted avg       0.80      0.80      0.80       528\n",
      "\n",
      "[[243  47]\n",
      " [ 60 178]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7973484848484849\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "3. SUPPORT VECTOR MACHINE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       290\n",
      "           1       0.72      0.77      0.75       238\n",
      "\n",
      "    accuracy                           0.76       528\n",
      "   macro avg       0.76      0.76      0.76       528\n",
      "weighted avg       0.77      0.76      0.76       528\n",
      "\n",
      "[[220  70]\n",
      " [ 55 183]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7632575757575758\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "4. NEURAL NETWORK:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       290\n",
      "           1       0.69      0.74      0.72       238\n",
      "\n",
      "    accuracy                           0.73       528\n",
      "   macro avg       0.73      0.74      0.73       528\n",
      "weighted avg       0.74      0.73      0.74       528\n",
      "\n",
      "[[212  78]\n",
      " [ 62 176]]\n",
      "\n",
      "\n",
      "Detailed Accuracy:\n",
      "0.7348484848484849\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "5. LINEAR REGRESSION:\n",
      "Root Mean Squared Error (RMSE):\n",
      "0.4253608020839769\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Performance of the different Models\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# DECISION TREE\n",
    "print(\"1. DECISION TREE:\")\n",
    "print(classification_report(y_test, dt_predict))\n",
    "print(confusion_matrix(y_test, dt_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, dt_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "print(\"2. RANDOM FOREST:\")\n",
    "print(classification_report(y_test, forest_predict))\n",
    "print(confusion_matrix(y_test, forest_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, forest_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# SUPPORT VECTOR MACHINE\n",
    "print(\"3. SUPPORT VECTOR MACHINE:\")\n",
    "print(classification_report(y_test, sup_predict))\n",
    "print(confusion_matrix(y_test, sup_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, sup_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# NEURAL NETWORK\n",
    "print(\"4. NEURAL NETWORK:\")\n",
    "print(classification_report(y_test, nn_predict))\n",
    "print(confusion_matrix(y_test, nn_predict))\n",
    "print(\"\\n\")\n",
    "print(\"Detailed Accuracy:\")\n",
    "print(accuracy_score(y_test, nn_predict))\n",
    "print(\"\\n\")\n",
    "print(\"----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# SPECIAL CASE: Linear Regression performs a regression and not a classification. \n",
    "# Thus, we have to apply other evaluation metrics, such as, e.g., root mean squared error.\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from math import sqrt\n",
    "\n",
    "print(\"5. LINEAR REGRESSION:\")\n",
    "print(\"Root Mean Squared Error (RMSE):\")\n",
    "print(sqrt(mean_squared_error(y_test, LR_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
